{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import math\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from keras.utils import np_utils\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sys\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import math\n",
    "import csv\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import urllib\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: binarytree in /opt/conda/lib/python3.6/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install binarytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bracketeer in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from bracketeer)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.6/site-packages (from bracketeer)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from bracketeer)\n",
      "Requirement already satisfied: binarytree in /opt/conda/lib/python3.6/site-packages (from bracketeer)\n",
      "Requirement already satisfied: python-dateutil>=2 in /opt/conda/lib/python3.6/site-packages (from pandas->bracketeer)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas->bracketeer)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from pandas->bracketeer)\n",
      "Requirement already satisfied: olefile in /opt/conda/lib/python3.6/site-packages (from Pillow->bracketeer)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->bracketeer)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages/cycler-0.10.0-py3.6.egg (from matplotlib->bracketeer)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /opt/conda/lib/python3.6/site-packages (from matplotlib->bracketeer)\n"
     ]
    }
   ],
   "source": [
    "!pip install bracketeer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the Data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_season_compact = pd.read_csv('./DataFiles//RegularSeasonCompactResults.csv')\n",
    "seasons = pd.read_csv('./DataFiles/Seasons.csv')\n",
    "teams = pd.read_csv('./DataFiles/Teams.csv')\n",
    "tourney_compact = pd.read_csv('./DataFiles/NCAATourneyCompactResults.csv')\n",
    "submission = pd.read_csv('./SampleSubmissionStage1.csv')\n",
    "tourney_seeds = pd.read_csv('./DataFiles/NCAATourneySeeds.csv')\n",
    "team_conferences = pd.read_csv('./DataFiles/TeamConferences.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamList = teams['TeamName'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Manipulate the Data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_Power6(team_id):\n",
    "    team = team_conferences[(team_conferences['Season'] == 2018) & (team_conferences['TeamID'] == team_id)]\n",
    "    # Can't find the team\n",
    "    if (len(team) == 0):\n",
    "        return 0\n",
    "    conf_name = team.iloc[0]['ConfAbbrev']\n",
    "    return int(conf_name == 'SEC' or conf_name == 'ACC'or conf_name == 'BIG_10' or conf_name == 'BIG_TEWELVE' or conf_name == 'BIG_EAST' or conf_name == 'PAC_12')\n",
    "\n",
    "def get_team_ID(name):\n",
    "    return teams[teams['TeamName'] == name].values[0][0]\n",
    "\n",
    "def get_team_name(team_id):\n",
    "    return teams[teams['TeamID'] == team_id].values[0][1]\n",
    "\n",
    "def list_for_URL(team_list):\n",
    "    team_list = [x.lower() for x in team_list]\n",
    "    team_list = [t.replace(' ', '-') for t in team_list]\n",
    "    team_list = [t.replace('st', 'state') for t in team_list]\n",
    "    team_list = [t.replace('northern-dakota', 'north-dakota') for t in team_list]\n",
    "    team_list = [t.replace('nc-', 'north-carolina-') for t in team_list]\n",
    "    team_list = [t.replace('fl-', 'florida-') for t in team_list]\n",
    "    team_list = [t.replace('ga-', 'georgia-') for t in team_list]\n",
    "    team_list = [t.replace('lsu', 'louisiana-state') for t in team_list]\n",
    "    team_list = [t.replace('maristate', 'marist') for t in team_list]\n",
    "    team_list = [t.replace('stateate', 'state') for t in team_list]\n",
    "    team_list = [t.replace('northernorthern', 'northern') for t in team_list]\n",
    "    team_list = [t.replace('usc', 'southern-california') for t in team_list]\n",
    "    base = 'http://www.sports-reference.com/cbb/schools/'\n",
    "    for team in team_list:\n",
    "        url = base + team + '/'\n",
    "list_for_URL(teamList);\n",
    "\n",
    "def handle_cases(arr):\n",
    "    indices = []\n",
    "    list_len = len(arr)\n",
    "    for i in range(list_len):\n",
    "        if (arr[i] == 'St' or arr[i] == 'FL'):\n",
    "            indices.append(i)\n",
    "    for p in indices:\n",
    "        arr[p-1] = arr[p-1] + ' ' + arr[p]\n",
    "    for i in range(len(indices)):\n",
    "        arr.remove(arr[indices[i] - i])\n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_tourney_appearances(team_id):\n",
    "    return len(tourney_seeds[tourney_seeds['TeamID'] == team_id].index)\n",
    "\n",
    "def different_csv(df):\n",
    "    # The stats CSV is a lit different in terms of naming so below is just some data cleaning\n",
    "    df['School'] = df['School'].replace('(State)', 'St', regex=True)\n",
    "    df['School'] = df['School'].replace('Albany (NY)', 'Albany NY')\n",
    "    df['School'] = df['School'].replace('Boston University', 'Boston Univ')\n",
    "    df['School'] = df['School'].replace('Central Michigan', 'C Michigan')\n",
    "    df['School'] = df['School'].replace('(Eastern)', 'E', regex=True)\n",
    "    df['School'] = df['School'].replace('Louisiana St', 'LSU')\n",
    "    df['School'] = df['School'].replace('North Carolina St', 'NC State')\n",
    "    df['School'] = df['School'].replace('Southern California', 'USC')\n",
    "    df['School'] = df['School'].replace('University of California', 'California', regex=True)\n",
    "    df['School'] = df['School'].replace('American', 'American Univ')\n",
    "    df['School'] = df['School'].replace('Arkansas-Little Rock', 'Ark Little Rock')\n",
    "    df['School'] = df['School'].replace('Arkansas-Pine Bluff', 'Ark Pine Bluff')\n",
    "    df['School'] = df['School'].replace('Bowling Green St', 'Bowling Green')\n",
    "    df['School'] = df['School'].replace('Brigham Young', 'BYU')\n",
    "    df['School'] = df['School'].replace('Cal Poly', 'Cal Poly SLO')\n",
    "    df['School'] = df['School'].replace('Centenary (LA)', 'Centenary')\n",
    "    df['School'] = df['School'].replace('Central Connecticut St', 'Central Conn')\n",
    "    df['School'] = df['School'].replace('Charleston Southern', 'Charleston So')\n",
    "    df['School'] = df['School'].replace('Coastal Carolina', 'Coastal Car')\n",
    "    df['School'] = df['School'].replace('College of Charleston', 'Col Charleston')\n",
    "    df['School'] = df['School'].replace('Cal St Fullerton', 'CS Fullerton')\n",
    "    df['School'] = df['School'].replace('Cal St Sacramento', 'CS Sacramento')\n",
    "    df['School'] = df['School'].replace('Cal St Bakersfield', 'CS Bakersfield')\n",
    "    df['School'] = df['School'].replace('Cal St Northridge', 'CS Northridge')\n",
    "    df['School'] = df['School'].replace('East Tennessee St', 'ETSU')\n",
    "    df['School'] = df['School'].replace('Detroit Mercy', 'Detroit')\n",
    "    df['School'] = df['School'].replace('Fairleigh Dickinson', 'F Dickinson')\n",
    "    df['School'] = df['School'].replace('Florida Atlantic', 'FL Atlantic')\n",
    "    df['School'] = df['School'].replace('Florida Gulf Coast', 'FL Gulf Coast')\n",
    "    df['School'] = df['School'].replace('Florida International', 'Florida Intl')\n",
    "    df['School'] = df['School'].replace('George Washington', 'G Washington')\n",
    "    df['School'] = df['School'].replace('Georgia Southern', 'Ga Southern')\n",
    "    df['School'] = df['School'].replace('Gardner-Webb', 'Gardner Webb')\n",
    "    df['School'] = df['School'].replace('Illinois-Chicago', 'IL Chicago')\n",
    "    df['School'] = df['School'].replace('Kent St', 'Kent')\n",
    "    df['School'] = df['School'].replace('Long Island University', 'Long Island')\n",
    "    df['School'] = df['School'].replace('Loyola Marymount', 'Loy Marymount')\n",
    "    df['School'] = df['School'].replace('Loyola (MD)', 'Loyola MD')\n",
    "    df['School'] = df['School'].replace('Loyola (IL)', 'Loyola-Chicago')\n",
    "    df['School'] = df['School'].replace('Massachusetts', 'MA Lowell')\n",
    "    df['School'] = df['School'].replace('Maryland-Eastern Shore', 'MD E Shore')\n",
    "    df['School'] = df['School'].replace('Miami (FL)', 'Miami FL')\n",
    "    df['School'] = df['School'].replace('Miami (OH)', 'Miami OH')\n",
    "    df['School'] = df['School'].replace('Missouri-Kansas City', 'Missouri KC')\n",
    "    df['School'] = df['School'].replace('Monmouth', 'Monmouth NJ')\n",
    "    df['School'] = df['School'].replace('Mississippi Valley St', 'MS Valley St')\n",
    "    df['School'] = df['School'].replace('Montana St', 'MTSU')\n",
    "    df['School'] = df['School'].replace('Northern Colorado', 'N Colorado')\n",
    "    df['School'] = df['School'].replace('North Dakota St', 'N Dakota St')\n",
    "    df['School'] = df['School'].replace('Northern Illinois', 'N Illinois')\n",
    "    df['School'] = df['School'].replace('Northern Kentucky', 'N Kentucky')\n",
    "    df['School'] = df['School'].replace('North Carolina A&T', 'NC A&T')\n",
    "    df['School'] = df['School'].replace('North Carolina Central', 'NC Central')\n",
    "    df['School'] = df['School'].replace('Pennsylvania', 'Penn')\n",
    "    df['School'] = df['School'].replace('South Carolina St', 'S Carolina St')\n",
    "    df['School'] = df['School'].replace('Southern Illinois', 'S Illinois')\n",
    "    df['School'] = df['School'].replace('UC-Santa Barbara', 'Santa Barbara')\n",
    "    df['School'] = df['School'].replace('Southeastern Louisiana', 'SE Louisiana')\n",
    "    df['School'] = df['School'].replace('Southeast Missouri St', 'SE Missouri St')\n",
    "    df['School'] = df['School'].replace('Stephen F. Austin', 'SF Austin')\n",
    "    df['School'] = df['School'].replace('Southern Methodist', 'SMU')\n",
    "    df['School'] = df['School'].replace('Southern Mississippi', 'Southern Miss')\n",
    "    df['School'] = df['School'].replace('Southern', 'Southern Univ')\n",
    "    df['School'] = df['School'].replace('St. Bonaventure', 'St Bonaventure')\n",
    "    df['School'] = df['School'].replace('St. Francis (NY)', 'St Francis NY')\n",
    "    df['School'] = df['School'].replace('Saint Francis (PA)', 'St Francis PA')\n",
    "    df['School'] = df['School'].replace('St. John\\'s (NY)', 'St John\\'s')\n",
    "    df['School'] = df['School'].replace('Saint Joseph\\'s', 'St Joseph\\'s PA')\n",
    "    df['School'] = df['School'].replace('Saint Louis', 'St Louis')\n",
    "    df['School'] = df['School'].replace('Saint Mary\\'s (CA)', 'St Mary\\'s CA')\n",
    "    df['School'] = df['School'].replace('Mount Saint Mary\\'s', 'Mt St Mary\\'s')\n",
    "    df['School'] = df['School'].replace('Saint Peter\\'s', 'St Peter\\'s')\n",
    "    df['School'] = df['School'].replace('Texas A&M-Corpus Christian', 'TAM C. Christian')\n",
    "    df['School'] = df['School'].replace('Texas Christian', 'TCU')\n",
    "    df['School'] = df['School'].replace('Tennessee-Martin', 'TN Martin')\n",
    "    df['School'] = df['School'].replace('Texas-Rio Grande Valley', 'UTRGV')\n",
    "    df['School'] = df['School'].replace('Texas Southern', 'TX Southern')\n",
    "    df['School'] = df['School'].replace('Alabama-Birmingham', 'UAB')\n",
    "    df['School'] = df['School'].replace('UC-Davis', 'UC Davis')\n",
    "    df['School'] = df['School'].replace('UC-Irvine', 'UC Irvine')\n",
    "    df['School'] = df['School'].replace('UC-Riverside', 'UC Riverside')\n",
    "    df['School'] = df['School'].replace('Central Florida', 'UCF')\n",
    "    df['School'] = df['School'].replace('Louisiana-Lafayette', 'ULL')\n",
    "    df['School'] = df['School'].replace('Louisiana-Monroe', 'ULM')\n",
    "    df['School'] = df['School'].replace('Maryland-Baltimore County', 'UMBC')\n",
    "    df['School'] = df['School'].replace('North Carolina-Asheville', 'UNC Asheville')\n",
    "    df['School'] = df['School'].replace('North Carolina-Greensboro', 'UNC Greensboro')\n",
    "    df['School'] = df['School'].replace('North Carolina-Wilmington', 'UNC Wilmington')\n",
    "    df['School'] = df['School'].replace('Nevada-Las Vegas', 'UNLV')\n",
    "    df['School'] = df['School'].replace('Texas-Arlington', 'UT Arlington')\n",
    "    df['School'] = df['School'].replace('Texas-San Antonio', 'UT San Antonio')\n",
    "    df['School'] = df['School'].replace('Texas-El Paso', 'UTEP')\n",
    "    df['School'] = df['School'].replace('Virginia Commonwealth', 'VA Commonwealth')\n",
    "    df['School'] = df['School'].replace('Western Carolina', 'W Carolina')\n",
    "    df['School'] = df['School'].replace('Western Illinois', 'W Illinois')\n",
    "    df['School'] = df['School'].replace('Western Kentucky', 'WKU')\n",
    "    df['School'] = df['School'].replace('Western Michigan', 'W Michigan')\n",
    "    df['School'] = df['School'].replace('Abilene Christian', 'Abilene Chr')\n",
    "    df['School'] = df['School'].replace('Montana State', 'Montana St')\n",
    "    df['School'] = df['School'].replace('Central Arkansas', 'Cent Arkansas')\n",
    "    df['School'] = df['School'].replace('Houston Baptist', 'Houston Bap')\n",
    "    df['School'] = df['School'].replace('South Dakota St', 'S Dakota St')\n",
    "    df['School'] = df['School'].replace('Maryland-Eastern Shore', 'MD E Shore')\n",
    "    return df\n",
    "\n",
    "def home_advantage(row):\n",
    "    if (row == 'H'):\n",
    "        home = 1\n",
    "    if (row == 'A'):\n",
    "        home = -1\n",
    "    if (row == 'N'):\n",
    "        home = 0\n",
    "    return home\n",
    "\n",
    "def compare(id_1, id_2, year):\n",
    "    team_1 = get_season_data(id_1, year)\n",
    "    team_2 = get_season_data(id_2, year)\n",
    "    diff = [a - b for a, b in zip(team_1, team_2)]\n",
    "    return diff\n",
    "\n",
    "def input_normalizer(arr):\n",
    "    for i in range(arr.shape[1]):\n",
    "        min_val = min(arr[:,i])\n",
    "        max_val = max(arr[:,i])\n",
    "        arr[:,i] =  (arr[:,i] - min_val) / (max_val - min_val)\n",
    "    return arr\n",
    "\n",
    "def input_normalizer_2(X):\n",
    "    return (X - np.mean(X, axis = 0)) / np.std(X, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_data(team_id, year):\n",
    "    # The data frame below holds stats for every single game in the given year\n",
    "    year_data = reg_season_compact[reg_season_compact['Season'] == year]\n",
    "    # Finding number of points per game\n",
    "    games_won = year_data[year_data.WTeamID == team_id] \n",
    "    total_points_scored = games_won['WScore'].sum()\n",
    "    games_lost = year_data[year_data.LTeamID == team_id] \n",
    "    total_games = games_won.append(games_lost)\n",
    "    num_games = len(total_games.index)\n",
    "    total_points_scored += games_lost['LScore'].sum()\n",
    "    \n",
    "    # Finding number of points per game allowed\n",
    "    total_points_allowed = games_won['LScore'].sum()\n",
    "    total_points_allowed += games_lost['WScore'].sum()\n",
    "    \n",
    "    #Result of data from http://www.sports-reference.com/cbb\n",
    "    stats_SOS = pd.read_csv('./MM_Stats/MM_Stats_'+str(year)+'.csv')\n",
    "    stats_SOS = different_csv(stats_SOS)\n",
    "    rankings = pd.read_csv('./Rankings/Rankings_'+str(year)+'.csv')\n",
    "    rankings = different_csv(rankings)\n",
    "    \n",
    "    name = get_team_name(team_id)\n",
    "    team = stats_SOS[stats_SOS['School'] == name]\n",
    "    team_ranking = rankings[rankings['School'] == name]\n",
    "    if (len(team.index) == 0 or len(team_ranking.index) == 0): #Can't find the team\n",
    "        total_3s_made = 0\n",
    "        total_turnovers = 0\n",
    "        total_assists = 0\n",
    "        sos = 0\n",
    "        total_rebounds = 0\n",
    "        srs = 0\n",
    "        total_steals = 0\n",
    "    else:\n",
    "        total_3s_made = team['X3P'].values[0]\n",
    "        total_turnovers = team['TOV'].values[0]\n",
    "        if (math.isnan(total_turnovers)):\n",
    "            total_turnovers = 0\n",
    "        total_assists = team['AST'].values[0]\n",
    "        if (math.isnan(total_assists)):\n",
    "            total_assists = 0\n",
    "        sos = team['SOS'].values[0]\n",
    "        srs = team['SRS'].values[0]\n",
    "        total_rebounds = team['TRB'].values[0]\n",
    "        if (math.isnan(total_rebounds)):\n",
    "            total_rebounds = 0\n",
    "        total_steals = team['STL'].values[0]\n",
    "        if (math.isnan(total_steals)):\n",
    "            total_steals = 0\n",
    "    \n",
    "    #Finding tournament seed for that year\n",
    "    tourney_year = tourney_seeds[tourney_seeds['Season'] == year]\n",
    "    seed = tourney_year[tourney_year['TeamID'] == team_id]\n",
    "    if (len(seed.index) != 0):\n",
    "        seed = seed.values[0][1]\n",
    "        tournament_seed = int(seed[1:3])\n",
    "    else:\n",
    "        tournament_seed = 25 #Not sure how to represent if a team didn't make the tourney\n",
    "    \n",
    "    # Finding number of wins and losses\n",
    "    num_wins = len(games_won.index)\n",
    "    # There are some teams who may have dropped to Division 2, so they won't have games \n",
    "    # a certain year. In this case, we don't want to divide by 0, so we'll just set the\n",
    "    # averages to 0 instead\n",
    "    if num_games == 0:\n",
    "        avg_points_scored = 0\n",
    "        avg_points_allowed = 0\n",
    "        avg_3s_made = 0\n",
    "        avg_turnovers = 0\n",
    "        avg_assists = 0\n",
    "        avg_rebounds = 0\n",
    "        avg_steals = 0\n",
    "    else:\n",
    "        avg_points_scored = total_points_scored/num_games\n",
    "        avg_points_allowed = total_points_allowed/num_games\n",
    "        avg_3s_made = total_3s_made/num_games\n",
    "        avg_turnovers = total_turnovers/num_games\n",
    "        avg_assists = total_assists/num_games\n",
    "        avg_rebounds = total_rebounds/num_games\n",
    "        avg_steals = total_steals/num_games\n",
    "    return [num_wins, avg_points_scored, avg_points_allowed, check_Power6(team_id), avg_3s_made, avg_assists, avg_turnovers,\n",
    "           tournament_seed, sos, srs, avg_rebounds, avg_steals, get_tourney_appearances(team_id)]\n",
    "\n",
    "def create_season_dict(year):\n",
    "    season_dictionary = collections.defaultdict(list)\n",
    "    for team in teamList:\n",
    "        team_id = teams[teams['TeamName'] == team].values[0][0]\n",
    "        team_vector = get_season_data(team_id, year)\n",
    "        season_dictionary[team_id] = team_vector\n",
    "    return season_dictionary\n",
    "\n",
    "def train_test(years, save_years):\n",
    "    total_num_games = 0\n",
    "    for year in years:\n",
    "        season = reg_season_compact[reg_season_compact['Season'] == year]\n",
    "        total_num_games += len(season.index)\n",
    "        tourney = tourney_compact[tourney_compact['Season'] == year]\n",
    "        total_num_games += len(tourney.index)\n",
    "    num_features = len(get_season_data(1181,2012)) #Just choosing a random team and seeing the dimensionality of the vector\n",
    "    xTrain = np.zeros(( total_num_games, num_features + 1))\n",
    "    yTrain = np.zeros(( total_num_games ))\n",
    "    index_counter = 0\n",
    "    for year in years:\n",
    "        team_vectors = create_season_dict(year)\n",
    "        season = reg_season_compact[reg_season_compact['Season'] == year]\n",
    "        num_games_in_season = len(season.index)\n",
    "        tourney = tourney_compact[tourney_compact['Season'] == year]\n",
    "        num_games_in_season += len(tourney.index)\n",
    "        xTrainSeason = np.zeros(( num_games_in_season, num_features + 1))\n",
    "        yTrainSeason = np.zeros(( num_games_in_season ))\n",
    "        counter = 0\n",
    "        for index, row in season.iterrows():\n",
    "            winning_team = row['WTeamID']\n",
    "            winning_vector = team_vectors[winning_team]\n",
    "            losing_team = row['LTeamID']\n",
    "            losing_vector = team_vectors[losing_team]\n",
    "            diff = [a - b for a, b in zip(winning_vector, losing_vector)]\n",
    "            home = home_advantage(row['WLoc'])\n",
    "            if (counter % 2 == 0):\n",
    "                diff.append(home) \n",
    "                xTrainSeason[counter] = diff\n",
    "                yTrainSeason[counter] = 1\n",
    "            else:\n",
    "                diff.append(-home)\n",
    "                xTrainSeason[counter] = [ -p for p in diff]\n",
    "                yTrainSeason[counter] = 0\n",
    "            counter += 1\n",
    "        for index, row in tourney.iterrows():\n",
    "            winning_team = row['WTeamID']\n",
    "            winning_vector = team_vectors[winning_team]\n",
    "            losing_team = row['LTeamID']\n",
    "            losing_vector = team_vectors[losing_team]\n",
    "            diff = [a - b for a, b in zip(winning_vector, losing_vector)]\n",
    "            home = 0 #All tournament games are neutral\n",
    "            if (counter % 2 == 0):\n",
    "                diff.append(home) \n",
    "                xTrainSeason[counter] = diff\n",
    "                yTrainSeason[counter] = 1\n",
    "            else:\n",
    "                diff.append(-home)\n",
    "                xTrainSeason[counter] = [ -p for p in diff]\n",
    "                yTrainSeason[counter] = 0\n",
    "            counter += 1\n",
    "        xTrain[index_counter:num_games_in_season+index_counter] = xTrainSeason\n",
    "        yTrain[index_counter:num_games_in_season+index_counter] = yTrainSeason\n",
    "        index_counter += num_games_in_season\n",
    "        print ('Finished year:', year)\n",
    "        if (year in save_years):\n",
    "            np.save('./Team_Vectors/' + str(year) + 'TeamVectors', team_vectors)\n",
    "    return xTrain, yTrain\n",
    "\n",
    "def create_save(years, save_years):\n",
    "    xTrain, yTrain = train_test(years, save_years)\n",
    "    np.save('./xTrain_2018.npy', xTrain)\n",
    "    np.save('./yTrain_2018.npy', yTrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is already a precomputed xTrain and yTrain.\n",
      "Do you want to remove these files and create a new training set? (y/n) n\n",
      "Okay, going to exit now.\n"
     ]
    }
   ],
   "source": [
    "years = range(1993,2018)\n",
    "# Saves the team vectors for the following years\n",
    "save_years = range(2014,2018)\n",
    "if os.path.exists(\"./xTrain_2018.npy\") and os.path.exists(\"./yTrain_2018.npy\"):\n",
    "    print ('There is already a precomputed xTrain and yTrain.')\n",
    "    response = input('Do you want to remove these files and create a new training set? (y/n) ')\n",
    "    if (response == 'y'):\n",
    "        os.remove(\"./xTrain_2018.npy\")\n",
    "        os.remove(\"./yTrain_2018.npy\")\n",
    "        create_save(years, save_years)\n",
    "    else: \n",
    "        print ('Okay, going to exit now.')\n",
    "else:\n",
    "    create_save(years, save_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of xTrain: (120575, 14)\n",
      "Shape of yTrain: (120575,)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"./xTrain_2018.npy\") and os.path.exists(\"./yTrain_2018.npy\"):\n",
    "    xTrain = np.load(\"./xTrain_2018.npy\")\n",
    "    yTrain = np.load(\"./yTrain_2018.npy\")\n",
    "    print (\"Shape of xTrain:\", xTrain.shape)\n",
    "    print (\"Shape of yTrain:\", yTrain.shape)\n",
    "else:\n",
    "    print ('We need a training set! Run dataPreprocessing.py')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the Submission csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./SampleSubmissionStage1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All the Models to Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tree.DecisionTreeClassifier()\n",
    "#model = tree.DecisionTreeRegressor()\n",
    "#model = linear_model.LogisticRegression()\n",
    "#model = linear_model.BayesianRidge()\n",
    "#model = linear_model.Lasso()\n",
    "#model = svm.SVC()\n",
    "#model = svm.SVR()\n",
    "#model = linear_model.Ridge(alpha = 0.5)\n",
    "#model = AdaBoostClassifier(n_estimators=100)\n",
    "#model = GradientBoostingClassifier(n_estimators=100)\n",
    "#model = GradientBoostingRegressor(n_estimators=100, max_depth=5)\n",
    "#model = RandomForestClassifier(n_estimators=64)\n",
    "#model = KNeighborsClassifier(n_neighbors=39)\n",
    "#neuralNetwork(10)\n",
    "#model = VotingClassifier(estimators=[('GBR', model1), ('BR', model2), ('KNN', model3)], voting='soft')\n",
    "#model = LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Importing Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run #0. Accuracy = 0.7615445859872612\n",
      "Finished run #1. Accuracy = 0.7624734607218684\n",
      "Finished run #2. Accuracy = 0.7615114118895966\n",
      "Finished run #3. Accuracy = 0.7616772823779193\n",
      "Finished run #4. Accuracy = 0.7687101910828026\n",
      "Finished run #5. Accuracy = 0.7624734607218684\n",
      "Finished run #6. Accuracy = 0.7616109341825902\n",
      "Finished run #7. Accuracy = 0.7622412420382165\n",
      "Finished run #8. Accuracy = 0.7612460191082803\n",
      "Finished run #9. Accuracy = 0.759952229299363\n",
      "Finished run #10. Accuracy = 0.7631701167728238\n",
      "Finished run #11. Accuracy = 0.7646629511677282\n",
      "Finished run #12. Accuracy = 0.7624734607218684\n",
      "Finished run #13. Accuracy = 0.7668524416135881\n",
      "Finished run #14. Accuracy = 0.7622412420382165\n",
      "Finished run #15. Accuracy = 0.7624402866242038\n",
      "The average accuracy is:  0.7628300822717622\n"
     ]
    }
   ],
   "source": [
    "model1 = LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=0.1)\n",
    "model = CalibratedClassifierCV(model1)\n",
    "\n",
    "categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Seed','SOS',\\\n",
    "            'SRS', 'RPG', 'SPG', 'Tourney Appearances','Location']\n",
    "accuracy=[]\n",
    "num_trials = 16\n",
    "\n",
    "for i in range(num_trials):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xTrain, yTrain)\n",
    "    results = model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    preds[preds < .5] = 0\n",
    "    preds[preds >= .5] = 1\n",
    "    local_accuracy = np.mean(preds == y_test)\n",
    "    accuracy.append(local_accuracy)\n",
    "    print(\"Finished run #\" + str(i) + \". Accuracy = \" + str(local_accuracy))\n",
    "print(\"The average accuracy is: \", sum(accuracy)/len(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict a Game.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_game(team_1_vector, team_2_vector, home):\n",
    "    diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n",
    "    diff.append(home)\n",
    "    # Depending on the model you use, you will either need to return model.predict_proba or model.predict\n",
    "    # predict_proba = Linear Reg, Linear SVC\n",
    "    # predict = Gradient Boosted\n",
    "\n",
    "    return model.predict_proba([diff])[0][1]\n",
    "    #return model.predict([diff])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_team_vectors(years):\n",
    "    list_dictionaries = []\n",
    "    for year in years:\n",
    "        current_vectors = np.load(\"./Team_Vectors/\" + str(year) + \"TeamVectors.npy\").item()\n",
    "        list_dictionaries.append(current_vectors)\n",
    "    return list_dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the team vectors\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "def create_prediction():\n",
    "    if os.path.exists(\"result.csv\"):\n",
    "        os.remove(\"result.csv\")\n",
    "    # The years that we want to predict for\n",
    "    years = range(2014,2018)\n",
    "    list_dictionaries = load_team_vectors(years)\n",
    "    print (\"Loaded the team vectors\")\n",
    "    results = [[0 for x in range(2)] for x in range(len(submission.index))]\n",
    "    for index, row in submission.iterrows():\n",
    "        matchup = row['ID']\n",
    "        year = int(matchup[0:4])\n",
    "        team_vectors = list_dictionaries[year - years[0]]\n",
    "        team_1_ID = int(matchup[5:9])\n",
    "        team_2_ID = int(matchup[10:14])\n",
    "        team_1_vector = team_vectors[team_1_ID]\n",
    "        team_2_vector = team_vectors[team_2_ID]\n",
    "        pred = predict_game(team_1_vector, team_2_vector, 0)\n",
    "        results[index][0] = matchup\n",
    "        results[index][1] = pred\n",
    "    results = pd.np.array(results)\n",
    "    first_row = [[0 for x in range(2)] for x in range(1)]\n",
    "    first_row[0][0] = 'ID'\n",
    "    first_row[0][1] = 'Pred'\n",
    "    with open(\"result.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(first_row)\n",
    "        writer.writerows(results)\n",
    "    print(\"All Done!\")\n",
    "\n",
    "create_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run #0. Accuracy = 0.7602176220806794\n",
      "Finished run #1. Accuracy = 0.7635018577494692\n",
      "Finished run #2. Accuracy = 0.7628715498938429\n",
      "Finished run #3. Accuracy = 0.7591228768577495\n",
      "Finished run #4. Accuracy = 0.7563362526539278\n",
      "The average accuracy is:  0.7604100318471338\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(loss='deviance', learning_rate=0.05, max_depth=6, n_estimators=500, max_features='log2')\n",
    " \n",
    "categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Seed','SOS',\\\n",
    "            'SRS', 'RPG', 'SPG', 'Tourney Appearances','Location']\n",
    "accuracy=[]\n",
    "num_trials = 5\n",
    "\n",
    "for i in range(num_trials):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xTrain, yTrain)\n",
    "    results = model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    preds[preds < .5] = 0\n",
    "    preds[preds >= .5] = 1\n",
    "    local_accuracy = np.mean(preds == y_test)\n",
    "    accuracy.append(local_accuracy)\n",
    "    print(\"Finished run #\" + str(i) + \". Accuracy = \" + str(local_accuracy))\n",
    "print(\"The average accuracy is: \", sum(accuracy)/len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_game(team_1_vector, team_2_vector, home):\n",
    "    diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n",
    "    diff.append(home)\n",
    "    # Depending on the model you use, you will either need to return model.predict_proba or model.predict\n",
    "    # predict_proba = Linear Reg, Linear SVC\n",
    "    # predict = Gradient Boosted\n",
    "\n",
    "    return model.predict_proba([diff])[0][1]\n",
    "    #return model.predict([diff])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_team_vectors(years):\n",
    "    list_dictionaries = []\n",
    "    for year in years:\n",
    "        current_vectors = np.load(\"./Team_Vectors/\" + str(year) + \"TeamVectors.npy\").item()\n",
    "        list_dictionaries.append(current_vectors)\n",
    "    return list_dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the team vectors\n"
     ]
    }
   ],
   "source": [
    "def create_prediction():\n",
    "    if os.path.exists(\"result.csv\"):\n",
    "        os.remove(\"result.csv\")\n",
    "    # The years that we want to predict for\n",
    "    years = range(2014,2018)\n",
    "    list_dictionaries = load_team_vectors(years)\n",
    "    print (\"Loaded the team vectors\")\n",
    "    results = [[0 for x in range(2)] for x in range(len(submission.index))]\n",
    "    for index, row in submission.iterrows():\n",
    "        matchup = row['ID']\n",
    "        year = int(matchup[0:4])\n",
    "        team_vectors = list_dictionaries[year - years[0]]\n",
    "        team_1_ID = int(matchup[5:9])\n",
    "        team_2_ID = int(matchup[10:14])\n",
    "        team_1_vector = team_vectors[team_1_ID]\n",
    "        team_2_vector = team_vectors[team_2_ID]\n",
    "        pred = predict_game(team_1_vector, team_2_vector, 0)\n",
    "        results[index][0] = matchup\n",
    "        results[index][1] = pred\n",
    "    results = pd.np.array(results)\n",
    "    first_row = [[0 for x in range(2)] for x in range(1)]\n",
    "    first_row[0][0] = 'ID'\n",
    "    first_row[0][1] = 'Pred'\n",
    "    with open(\"result_GBC.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(first_row)\n",
    "        writer.writerows(results)\n",
    "\n",
    "create_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(14, input_dim=X_train.shape[1], activation='relu'))\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "# model.add(Dropout(.5))\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dense(4, activation='relu'))\n",
    "# model.add(Dropout(.15))\n",
    "# model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " \n",
    "# categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Seed','SOS',\\\n",
    "#             'SRS', 'RPG', 'SPG', 'Tourney Appearances','Location']\n",
    "# accuracy=[]\n",
    "# num_trials = 1\n",
    "\n",
    "# for i in range(num_trials):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(xTrain, yTrain)\n",
    "#     results = model.fit(np.array(X_train), np.array(y_train), epochs=20, batch_size=10)\n",
    "#     #model.fit(np.array(train_X),np.array(train_Y), epochs=20, batch_size=10)\n",
    "\n",
    "#     preds = model.predict(X_test)\n",
    "\n",
    "#     preds[preds < .5] = 0\n",
    "#     preds[preds >= .5] = 1\n",
    "#     local_accuracy = np.mean(preds == y_test)\n",
    "#     accuracy.append(local_accuracy)\n",
    "#     print(\"Finished run #\" + str(i) + \". Accuracy = \" + str(local_accuracy))\n",
    "# print(\"The average accuracy is: \", sum(accuracy)/len(accuracy))\n",
    "\n",
    "# def predict_game(team_1_vector, team_2_vector, home):\n",
    "#     diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n",
    "#     diff.append(home)\n",
    "#     # Depending on the model you use, you will either need to return model.predict_proba or model.predict\n",
    "#     # predict_proba = Linear Reg, Linear SVC\n",
    "#     # predict = Gradient Boosted\n",
    "\n",
    "#     return model.predict_proba([diff])[0][1]\n",
    "#     #return model.predict([diff])[0]\n",
    "\n",
    "# def load_team_vectors(years):\n",
    "#     list_dictionaries = []\n",
    "#     for year in years:\n",
    "#         current_vectors = np.load(\"./Team_Vectors/\" + str(year) + \"TeamVectors.npy\").item()\n",
    "#         list_dictionaries.append(current_vectors)\n",
    "#     return list_dictionaries\n",
    "\n",
    "# def create_prediction():\n",
    "#     if os.path.exists(\"result.csv\"):\n",
    "#         os.remove(\"result.csv\")\n",
    "#     # The years that we want to predict for\n",
    "#     years = range(2014,2018)\n",
    "#     list_dictionaries = load_team_vectors(years)\n",
    "#     print (\"Loaded the team vectors\")\n",
    "#     results = [[0 for x in range(2)] for x in range(len(submission.index))]\n",
    "#     for index, row in submission.iterrows():\n",
    "#         matchup = row['ID']\n",
    "#         year = int(matchup[0:4])\n",
    "#         team_vectors = list_dictionaries[year - years[0]]\n",
    "#         team_1_ID = int(matchup[5:9])\n",
    "#         team_2_ID = int(matchup[10:14])\n",
    "#         team_1_vector = team_vectors[team_1_ID]\n",
    "#         team_2_vector = team_vectors[team_2_ID]\n",
    "#         pred = predict_game(team_1_vector, team_2_vector, 0)\n",
    "#         results[index][0] = matchup\n",
    "#         results[index][1] = pred\n",
    "#     results = pd.np.array(results)\n",
    "#     first_row = [[0 for x in range(2)] for x in range(1)]\n",
    "#     first_row[0][0] = 'ID'\n",
    "#     first_row[0][1] = 'Pred'\n",
    "#     with open(\"result_keras.csv\", \"w\") as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerows(first_row)\n",
    "#         writer.writerows(results)\n",
    "\n",
    "# create_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so the Neural Net didn't work that well, need to fix that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run #0. Accuracy = 0.758359872611465\n",
      "Finished run #1. Accuracy = 0.752687101910828\n",
      "Finished run #2. Accuracy = 0.7591228768577495\n",
      "Finished run #3. Accuracy = 0.7595873142250531\n",
      "Finished run #4. Accuracy = 0.7573646496815286\n",
      "Finished run #5. Accuracy = 0.7535164543524416\n",
      "Finished run #6. Accuracy = 0.7520236199575372\n",
      "Finished run #7. Accuracy = 0.7519240976645435\n",
      "Finished run #8. Accuracy = 0.7534501061571125\n",
      "Finished run #9. Accuracy = 0.7588906581740976\n",
      "Finished run #10. Accuracy = 0.7511279193205945\n",
      "Finished run #11. Accuracy = 0.7554405520169851\n",
      "Finished run #12. Accuracy = 0.7579617834394905\n",
      "Finished run #13. Accuracy = 0.7530188428874734\n",
      "Finished run #14. Accuracy = 0.758426220806794\n",
      "The average accuracy is:  0.7555268046709129\n",
      "Loaded the team vectors\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(n_estimators=100, learning_rate=0.25, algorithm='SAMME')\n",
    "\n",
    "categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Seed','SOS',\\\n",
    "            'SRS', 'RPG', 'SPG', 'Tourney Appearances','Location']\n",
    "accuracy=[]\n",
    "num_trials = 15\n",
    "\n",
    "for i in range(num_trials):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xTrain, yTrain)\n",
    "    results = model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    preds[preds < .5] = 0\n",
    "    preds[preds >= .5] = 1\n",
    "    local_accuracy = np.mean(preds == y_test)\n",
    "    accuracy.append(local_accuracy)\n",
    "    print(\"Finished run #\" + str(i) + \". Accuracy = \" + str(local_accuracy))\n",
    "print(\"The average accuracy is: \", sum(accuracy)/len(accuracy))\n",
    "\n",
    "def predict_game(team_1_vector, team_2_vector, home):\n",
    "    diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n",
    "    diff.append(home)\n",
    "    # Depending on the model you use, you will either need to return model.predict_proba or model.predict\n",
    "    # predict_proba = Linear Reg, Linear SVC\n",
    "    # predict = Gradient Boosted\n",
    "\n",
    "    return model.predict_proba([diff])[0][1]\n",
    "    #return model.predict([diff])[0]\n",
    "\n",
    "def create_prediction():\n",
    "    if os.path.exists(\"result.csv\"):\n",
    "        os.remove(\"result.csv\")\n",
    "    # The years that we want to predict for\n",
    "    years = range(2014,2018)\n",
    "    list_dictionaries = load_team_vectors(years)\n",
    "    print (\"Loaded the team vectors\")\n",
    "    results = [[0 for x in range(2)] for x in range(len(submission.index))]\n",
    "    for index, row in submission.iterrows():\n",
    "        matchup = row['ID']\n",
    "        year = int(matchup[0:4])\n",
    "        team_vectors = list_dictionaries[year - years[0]]\n",
    "        team_1_ID = int(matchup[5:9])\n",
    "        team_2_ID = int(matchup[10:14])\n",
    "        team_1_vector = team_vectors[team_1_ID]\n",
    "        team_2_vector = team_vectors[team_2_ID]\n",
    "        pred = predict_game(team_1_vector, team_2_vector, 0)\n",
    "        results[index][0] = matchup\n",
    "        results[index][1] = pred\n",
    "    results = pd.np.array(results)\n",
    "    first_row = [[0 for x in range(2)] for x in range(1)]\n",
    "    first_row[0][0] = 'ID'\n",
    "    first_row[0][1] = 'Pred'\n",
    "    with open(\"result_ada.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(first_row)\n",
    "        writer.writerows(results)\n",
    "\n",
    "create_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run #0. Accuracy = 0.7283041401273885\n",
      "Finished run #1. Accuracy = 0.7247545116772823\n",
      "Finished run #2. Accuracy = 0.7231621549893843\n",
      "Finished run #3. Accuracy = 0.726015127388535\n",
      "Finished run #4. Accuracy = 0.7283704883227177\n",
      "Finished run #5. Accuracy = 0.7266786093418259\n",
      "Finished run #6. Accuracy = 0.725583864118896\n",
      "Finished run #7. Accuracy = 0.7274084394904459\n",
      "Finished run #8. Accuracy = 0.7258492569002123\n",
      "Finished run #9. Accuracy = 0.7278728768577495\n",
      "Finished run #10. Accuracy = 0.7287354033970276\n",
      "Finished run #11. Accuracy = 0.7240246815286624\n",
      "Finished run #12. Accuracy = 0.7274747876857749\n",
      "Finished run #13. Accuracy = 0.7228304140127388\n",
      "Finished run #14. Accuracy = 0.727109872611465\n",
      "Finished run #15. Accuracy = 0.7245886411889597\n",
      "The average accuracy is:  0.7261727043524416\n",
      "Loaded the team vectors\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=125, criterion='entropy', max_features='log2', min_samples_split=2)\n",
    "\n",
    "categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Seed','SOS',\\\n",
    "            'SRS', 'RPG', 'SPG', 'Tourney Appearances','Location']\n",
    "accuracy=[]\n",
    "num_trials = 16\n",
    "\n",
    "for i in range(num_trials):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xTrain, yTrain)\n",
    "    results = model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    preds[preds < .5] = 0\n",
    "    preds[preds >= .5] = 1\n",
    "    local_accuracy = np.mean(preds == y_test)\n",
    "    accuracy.append(local_accuracy)\n",
    "    print(\"Finished run #\" + str(i) + \". Accuracy = \" + str(local_accuracy))\n",
    "print(\"The average accuracy is: \", sum(accuracy)/len(accuracy))\n",
    "\n",
    "def predict_game(team_1_vector, team_2_vector, home):\n",
    "    diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n",
    "    diff.append(home)\n",
    "    # Depending on the model you use, you will either need to return model.predict_proba or model.predict\n",
    "    # predict_proba = Linear Reg, Linear SVC\n",
    "    # predict = Gradient Boosted\n",
    "\n",
    "    return model.predict_proba([diff])[0][1]\n",
    "    #return model.predict([diff])[0]\n",
    "\n",
    "def create_prediction():\n",
    "    if os.path.exists(\"result.csv\"):\n",
    "        os.remove(\"result.csv\")\n",
    "    # The years that we want to predict for\n",
    "    years = range(2014,2018)\n",
    "    list_dictionaries = load_team_vectors(years)\n",
    "    print (\"Loaded the team vectors\")\n",
    "    results = [[0 for x in range(2)] for x in range(len(submission.index))]\n",
    "    for index, row in submission.iterrows():\n",
    "        matchup = row['ID']\n",
    "        year = int(matchup[0:4])\n",
    "        team_vectors = list_dictionaries[year - years[0]]\n",
    "        team_1_ID = int(matchup[5:9])\n",
    "        team_2_ID = int(matchup[10:14])\n",
    "        team_1_vector = team_vectors[team_1_ID]\n",
    "        team_2_vector = team_vectors[team_2_ID]\n",
    "        pred = predict_game(team_1_vector, team_2_vector, 0)\n",
    "        results[index][0] = matchup\n",
    "        results[index][1] = pred\n",
    "    results = pd.np.array(results)\n",
    "    first_row = [[0 for x in range(2)] for x in range(1)]\n",
    "    first_row[0][0] = 'ID'\n",
    "    first_row[0][1] = 'Pred'\n",
    "    with open(\"result_rf.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(first_row)\n",
    "        writer.writerows(results)\n",
    "\n",
    "create_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression,  L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run #0. Accuracy = 0.7627720276008493\n",
      "Finished run #1. Accuracy = 0.7627720276008493\n",
      "Finished run #2. Accuracy = 0.7611133227176221\n",
      "Finished run #3. Accuracy = 0.7650942144373672\n",
      "Finished run #4. Accuracy = 0.7634355095541401\n",
      "Finished run #5. Accuracy = 0.7628052016985138\n",
      "Finished run #6. Accuracy = 0.762506634819533\n",
      "Finished run #7. Accuracy = 0.7625398089171974\n",
      "Finished run #8. Accuracy = 0.7655586518046709\n",
      "Finished run #9. Accuracy = 0.7605161889596603\n",
      "Finished run #10. Accuracy = 0.7621085456475584\n",
      "Finished run #11. Accuracy = 0.7597200106157113\n",
      "Finished run #12. Accuracy = 0.7604498407643312\n",
      "Finished run #13. Accuracy = 0.7606488853503185\n",
      "Finished run #14. Accuracy = 0.7617104564755839\n",
      "Finished run #15. Accuracy = 0.7657245222929936\n",
      "The average accuracy is:  0.7624672405785562\n",
      "Loaded the team vectors\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l1', C=0.5, max_iter=200)\n",
    "\n",
    "categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Seed','SOS',\\\n",
    "            'SRS', 'RPG', 'SPG', 'Tourney Appearances','Location']\n",
    "accuracy=[]\n",
    "num_trials = 16\n",
    "\n",
    "for i in range(num_trials):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xTrain, yTrain)\n",
    "    results = model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    preds[preds < .5] = 0\n",
    "    preds[preds >= .5] = 1\n",
    "    local_accuracy = np.mean(preds == y_test)\n",
    "    accuracy.append(local_accuracy)\n",
    "    print(\"Finished run #\" + str(i) + \". Accuracy = \" + str(local_accuracy))\n",
    "print(\"The average accuracy is: \", sum(accuracy)/len(accuracy))\n",
    "\n",
    "def predict_game(team_1_vector, team_2_vector, home):\n",
    "    diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n",
    "    diff.append(home)\n",
    "    # Depending on the model you use, you will either need to return model.predict_proba or model.predict\n",
    "    # predict_proba = Linear Reg, Linear SVC\n",
    "    # predict = Gradient Boosted\n",
    "\n",
    "    return model.predict_proba([diff])[0][1]\n",
    "    #return model.predict([diff])[0]\n",
    "\n",
    "def create_prediction():\n",
    "    if os.path.exists(\"result.csv\"):\n",
    "        os.remove(\"result.csv\")\n",
    "    # The years that we want to predict for\n",
    "    years = range(2014,2018)\n",
    "    list_dictionaries = load_team_vectors(years)\n",
    "    print (\"Loaded the team vectors\")\n",
    "    results = [[0 for x in range(2)] for x in range(len(submission.index))]\n",
    "    for index, row in submission.iterrows():\n",
    "        matchup = row['ID']\n",
    "        year = int(matchup[0:4])\n",
    "        team_vectors = list_dictionaries[year - years[0]]\n",
    "        team_1_ID = int(matchup[5:9])\n",
    "        team_2_ID = int(matchup[10:14])\n",
    "        team_1_vector = team_vectors[team_1_ID]\n",
    "        team_2_vector = team_vectors[team_2_ID]\n",
    "        pred = predict_game(team_1_vector, team_2_vector, 0)\n",
    "        results[index][0] = matchup\n",
    "        results[index][1] = pred\n",
    "    results = pd.np.array(results)\n",
    "    first_row = [[0 for x in range(2)] for x in range(1)]\n",
    "    first_row[0][0] = 'ID'\n",
    "    first_row[0][1] = 'Pred'\n",
    "    with open(\"result_rf.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(first_row)\n",
    "        writer.writerows(results)\n",
    "\n",
    "create_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression, L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run #0. Accuracy = 0.7654259554140127\n",
      "Finished run #1. Accuracy = 0.7587579617834395\n",
      "Finished run #2. Accuracy = 0.7624402866242038\n",
      "Finished run #3. Accuracy = 0.7596536624203821\n",
      "Finished run #4. Accuracy = 0.7607152335456475\n",
      "Finished run #5. Accuracy = 0.7609474522292994\n",
      "Finished run #6. Accuracy = 0.7621417197452229\n",
      "Finished run #7. Accuracy = 0.7589570063694268\n",
      "Finished run #8. Accuracy = 0.7576632165605095\n",
      "Finished run #9. Accuracy = 0.7602507961783439\n",
      "Finished run #10. Accuracy = 0.7627056794055201\n",
      "Finished run #11. Accuracy = 0.7630705944798302\n",
      "Finished run #12. Accuracy = 0.7571324309978769\n",
      "Finished run #13. Accuracy = 0.7620090233545648\n",
      "Finished run #14. Accuracy = 0.7621417197452229\n",
      "Finished run #15. Accuracy = 0.7608811040339702\n",
      "The average accuracy is:  0.7609308651804672\n",
      "Loaded the team vectors\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2', C=0.5, tol=0.00001, max_iter=500)\n",
    "\n",
    "categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Seed','SOS',\\\n",
    "            'SRS', 'RPG', 'SPG', 'Tourney Appearances','Location']\n",
    "accuracy=[]\n",
    "num_trials = 16\n",
    "\n",
    "for i in range(num_trials):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xTrain, yTrain)\n",
    "    results = model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    preds[preds < .5] = 0\n",
    "    preds[preds >= .5] = 1\n",
    "    local_accuracy = np.mean(preds == y_test)\n",
    "    accuracy.append(local_accuracy)\n",
    "    print(\"Finished run #\" + str(i) + \". Accuracy = \" + str(local_accuracy))\n",
    "print(\"The average accuracy is: \", sum(accuracy)/len(accuracy))\n",
    "\n",
    "def predict_game(team_1_vector, team_2_vector, home):\n",
    "    diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n",
    "    diff.append(home)\n",
    "    # Depending on the model you use, you will either need to return model.predict_proba or model.predict\n",
    "    # predict_proba = Linear Reg, Linear SVC\n",
    "    # predict = Gradient Boosted\n",
    "\n",
    "    return model.predict_proba([diff])[0][1]\n",
    "    #return model.predict([diff])[0]\n",
    "\n",
    "def create_prediction():\n",
    "    if os.path.exists(\"result.csv\"):\n",
    "        os.remove(\"result.csv\")\n",
    "    # The years that we want to predict for\n",
    "    years = range(2014,2018)\n",
    "    list_dictionaries = load_team_vectors(years)\n",
    "    print (\"Loaded the team vectors\")\n",
    "    results = [[0 for x in range(2)] for x in range(len(submission.index))]\n",
    "    for index, row in submission.iterrows():\n",
    "        matchup = row['ID']\n",
    "        year = int(matchup[0:4])\n",
    "        team_vectors = list_dictionaries[year - years[0]]\n",
    "        team_1_ID = int(matchup[5:9])\n",
    "        team_2_ID = int(matchup[10:14])\n",
    "        team_1_vector = team_vectors[team_1_ID]\n",
    "        team_2_vector = team_vectors[team_2_ID]\n",
    "        pred = predict_game(team_1_vector, team_2_vector, 0)\n",
    "        results[index][0] = matchup\n",
    "        results[index][1] = pred\n",
    "    results = pd.np.array(results)\n",
    "    first_row = [[0 for x in range(2)] for x in range(1)]\n",
    "    first_row[0][0] = 'ID'\n",
    "    first_row[0][1] = 'Pred'\n",
    "    with open(\"result_l2.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(first_row)\n",
    "        writer.writerows(results)\n",
    "    print('All Done!')\n",
    "create_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run #0. Accuracy = 0.7226977176220807\n",
      "Finished run #1. Accuracy = 0.7253184713375797\n",
      "Finished run #2. Accuracy = 0.7222996284501062\n",
      "Finished run #3. Accuracy = 0.7237592887473461\n",
      "Finished run #4. Accuracy = 0.7190817409766455\n",
      "Finished run #5. Accuracy = 0.7249203821656051\n",
      "Finished run #6. Accuracy = 0.7231289808917197\n",
      "Finished run #7. Accuracy = 0.7236597664543525\n",
      "Finished run #8. Accuracy = 0.7223328025477707\n",
      "Finished run #9. Accuracy = 0.7253848195329087\n",
      "Finished run #10. Accuracy = 0.7268444798301487\n",
      "Finished run #11. Accuracy = 0.7207736199575372\n",
      "Finished run #12. Accuracy = 0.7196788747346072\n",
      "Finished run #13. Accuracy = 0.7274747876857749\n",
      "Finished run #14. Accuracy = 0.7259156050955414\n",
      "Finished run #15. Accuracy = 0.7246218152866242\n",
      "The average accuracy is:  0.7236182988322718\n",
      "Loaded the team vectors\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Seed','SOS',\\\n",
    "            'SRS', 'RPG', 'SPG', 'Tourney Appearances','Location']\n",
    "accuracy=[]\n",
    "num_trials = 16\n",
    "\n",
    "for i in range(num_trials):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xTrain, yTrain)\n",
    "    results = model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    preds[preds < .5] = 0\n",
    "    preds[preds >= .5] = 1\n",
    "    local_accuracy = np.mean(preds == y_test)\n",
    "    accuracy.append(local_accuracy)\n",
    "    print(\"Finished run #\" + str(i) + \". Accuracy = \" + str(local_accuracy))\n",
    "print(\"The average accuracy is: \", sum(accuracy)/len(accuracy))\n",
    "\n",
    "def predict_game(team_1_vector, team_2_vector, home):\n",
    "    diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n",
    "    diff.append(home)\n",
    "    # Depending on the model you use, you will either need to return model.predict_proba or model.predict\n",
    "    # predict_proba = Linear Reg, Linear SVC\n",
    "    # predict = Gradient Boosted\n",
    "\n",
    "    return model.predict_proba([diff])[0][1]\n",
    "    #return model.predict([diff])[0]\n",
    "\n",
    "def create_prediction():\n",
    "    if os.path.exists(\"result.csv\"):\n",
    "        os.remove(\"result.csv\")\n",
    "    # The years that we want to predict for\n",
    "    years = range(2014,2018)\n",
    "    list_dictionaries = load_team_vectors(years)\n",
    "    print (\"Loaded the team vectors\")\n",
    "    results = [[0 for x in range(2)] for x in range(len(submission.index))]\n",
    "    for index, row in submission.iterrows():\n",
    "        matchup = row['ID']\n",
    "        year = int(matchup[0:4])\n",
    "        team_vectors = list_dictionaries[year - years[0]]\n",
    "        team_1_ID = int(matchup[5:9])\n",
    "        team_2_ID = int(matchup[10:14])\n",
    "        team_1_vector = team_vectors[team_1_ID]\n",
    "        team_2_vector = team_vectors[team_2_ID]\n",
    "        pred = predict_game(team_1_vector, team_2_vector, 0)\n",
    "        results[index][0] = matchup\n",
    "        results[index][1] = pred\n",
    "    results = pd.np.array(results)\n",
    "    first_row = [[0 for x in range(2)] for x in range(1)]\n",
    "    first_row[0][0] = 'ID'\n",
    "    first_row[0][1] = 'Pred'\n",
    "    with open(\"result_knn.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(first_row)\n",
    "        writer.writerows(results)\n",
    "    print('All Done!')\n",
    "create_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run #0. Accuracy = 0.49595276008492567\n",
      "Finished run #1. Accuracy = 0.4973792462845011\n",
      "Finished run #2. Accuracy = 0.498473991507431\n",
      "Finished run #3. Accuracy = 0.4971470276008493\n",
      "Finished run #4. Accuracy = 0.4984408174097665\n",
      "Finished run #5. Accuracy = 0.49727972399150744\n",
      "Finished run #6. Accuracy = 0.49910429936305734\n",
      "Finished run #7. Accuracy = 0.4993033439490446\n",
      "Finished run #8. Accuracy = 0.49850716560509556\n",
      "Finished run #9. Accuracy = 0.49980095541401276\n",
      "Finished run #10. Accuracy = 0.49920382165605093\n",
      "Finished run #11. Accuracy = 0.4958200636942675\n",
      "Finished run #12. Accuracy = 0.4963508492569002\n",
      "Finished run #13. Accuracy = 0.4955878450106157\n",
      "Finished run #14. Accuracy = 0.49781050955414013\n",
      "Finished run #15. Accuracy = 0.49913747346072185\n",
      "The average accuracy is:  0.4978312433651805\n",
      "Loaded the team vectors\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(loss='lad', learning_rate=.001, n_estimators=500, max_depth=6, min_samples_split=4)\n",
    "\n",
    "categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Seed','SOS',\\\n",
    "            'SRS', 'RPG', 'SPG', 'Tourney Appearances','Location']\n",
    "accuracy=[]\n",
    "num_trials = 16\n",
    "\n",
    "for i in range(num_trials):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xTrain, yTrain)\n",
    "    results = model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    preds[preds < .5] = 0\n",
    "    preds[preds >= .5] = 1\n",
    "    local_accuracy = np.mean(preds == y_test)\n",
    "    accuracy.append(local_accuracy)\n",
    "    print(\"Finished run #\" + str(i) + \". Accuracy = \" + str(local_accuracy))\n",
    "print(\"The average accuracy is: \", sum(accuracy)/len(accuracy))\n",
    "\n",
    "def predict_game(team_1_vector, team_2_vector, home):\n",
    "    diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n",
    "    diff.append(home)\n",
    "    # Depending on the model you use, you will either need to return model.predict_proba or model.predict\n",
    "    # predict_proba = Linear Reg, Linear SVC\n",
    "    # predict = Gradient Boosted\n",
    "\n",
    "    #return model.predict_proba([diff])[0][1]\n",
    "    return model.predict([diff])[0]\n",
    "\n",
    "def create_prediction():\n",
    "    if os.path.exists(\"result.csv\"):\n",
    "        os.remove(\"result.csv\")\n",
    "    # The years that we want to predict for\n",
    "    years = range(2014,2018)\n",
    "    list_dictionaries = load_team_vectors(years)\n",
    "    print (\"Loaded the team vectors\")\n",
    "    results = [[0 for x in range(2)] for x in range(len(submission.index))]\n",
    "    for index, row in submission.iterrows():\n",
    "        matchup = row['ID']\n",
    "        year = int(matchup[0:4])\n",
    "        team_vectors = list_dictionaries[year - years[0]]\n",
    "        team_1_ID = int(matchup[5:9])\n",
    "        team_2_ID = int(matchup[10:14])\n",
    "        team_1_vector = team_vectors[team_1_ID]\n",
    "        team_2_vector = team_vectors[team_2_ID]\n",
    "        pred = predict_game(team_1_vector, team_2_vector, 0)\n",
    "        results[index][0] = matchup\n",
    "        results[index][1] = pred\n",
    "    results = pd.np.array(results)\n",
    "    first_row = [[0 for x in range(2)] for x in range(1)]\n",
    "    first_row[0][0] = 'ID'\n",
    "    first_row[0][1] = 'Pred'\n",
    "    with open(\"result_knn.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(first_row)\n",
    "        writer.writerows(results)\n",
    "    print('All Done!')\n",
    "create_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run #0. Accuracy = 0.7660230891719745\n",
      "Finished run #1. Accuracy = 0.7651273885350318\n",
      "Finished run #2. Accuracy = 0.7606820594479831\n",
      "Finished run #3. Accuracy = 0.7641653397027601\n",
      "Finished run #4. Accuracy = 0.7612791932059448\n",
      "Finished run #5. Accuracy = 0.76453025477707\n",
      "Finished run #6. Accuracy = 0.7628383757961783\n",
      "Finished run #7. Accuracy = 0.7583266985138004\n",
      "Finished run #8. Accuracy = 0.7612460191082803\n",
      "Finished run #9. Accuracy = 0.7649615180467091\n",
      "Finished run #10. Accuracy = 0.7651273885350318\n",
      "Finished run #11. Accuracy = 0.7619426751592356\n",
      "Finished run #12. Accuracy = 0.7594214437367304\n",
      "Finished run #13. Accuracy = 0.7618763269639066\n",
      "Finished run #14. Accuracy = 0.7639662951167728\n",
      "Finished run #15. Accuracy = 0.7583930467091295\n",
      "The average accuracy is:  0.7624941945329088\n",
      "Loaded the team vectors\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "\n",
    "categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Seed','SOS',\\\n",
    "            'SRS', 'RPG', 'SPG', 'Tourney Appearances','Location']\n",
    "accuracy=[]\n",
    "num_trials = 16\n",
    "\n",
    "for i in range(num_trials):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xTrain, yTrain)\n",
    "    results = model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    preds[preds < .5] = 0\n",
    "    preds[preds >= .5] = 1\n",
    "    local_accuracy = np.mean(preds == y_test)\n",
    "    accuracy.append(local_accuracy)\n",
    "    print(\"Finished run #\" + str(i) + \". Accuracy = \" + str(local_accuracy))\n",
    "print(\"The average accuracy is: \", sum(accuracy)/len(accuracy))\n",
    "\n",
    "def predict_game(team_1_vector, team_2_vector, home):\n",
    "    diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n",
    "    diff.append(home)\n",
    "    # Depending on the model you use, you will either need to return model.predict_proba or model.predict\n",
    "    # predict_proba = Linear Reg, Linear SVC\n",
    "    # predict = Gradient Boosted\n",
    "\n",
    "    return model.predict_proba([diff])[0][1]\n",
    "    #return model.predict([diff])[0]\n",
    "\n",
    "def create_prediction():\n",
    "    if os.path.exists(\"result.csv\"):\n",
    "        os.remove(\"result.csv\")\n",
    "    # The years that we want to predict for\n",
    "    years = range(2014,2018)\n",
    "    list_dictionaries = load_team_vectors(years)\n",
    "    print (\"Loaded the team vectors\")\n",
    "    results = [[0 for x in range(2)] for x in range(len(submission.index))]\n",
    "    for index, row in submission.iterrows():\n",
    "        matchup = row['ID']\n",
    "        year = int(matchup[0:4])\n",
    "        team_vectors = list_dictionaries[year - years[0]]\n",
    "        team_1_ID = int(matchup[5:9])\n",
    "        team_2_ID = int(matchup[10:14])\n",
    "        team_1_vector = team_vectors[team_1_ID]\n",
    "        team_2_vector = team_vectors[team_2_ID]\n",
    "        pred = predict_game(team_1_vector, team_2_vector, 0)\n",
    "        results[index][0] = matchup\n",
    "        results[index][1] = pred\n",
    "    results = pd.np.array(results)\n",
    "    first_row = [[0 for x in range(2)] for x in range(1)]\n",
    "    first_row[0][0] = 'ID'\n",
    "    first_row[0][1] = 'Pred'\n",
    "    with open(\"result_gbclass.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(first_row)\n",
    "        writer.writerows(results)\n",
    "    print('All Done!')\n",
    "create_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NuSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run #0. Accuracy = 0.7038880042462845\n"
     ]
    }
   ],
   "source": [
    "model = NuSVC()\n",
    "\n",
    "categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Seed','SOS',\\\n",
    "            'SRS', 'RPG', 'SPG', 'Tourney Appearances','Location']\n",
    "accuracy=[]\n",
    "num_trials = 16\n",
    "\n",
    "for i in range(num_trials):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xTrain, yTrain)\n",
    "    results = model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    preds[preds < .5] = 0\n",
    "    preds[preds >= .5] = 1\n",
    "    local_accuracy = np.mean(preds == y_test)\n",
    "    accuracy.append(local_accuracy)\n",
    "    print(\"Finished run #\" + str(i) + \". Accuracy = \" + str(local_accuracy))\n",
    "print(\"The average accuracy is: \", sum(accuracy)/len(accuracy))\n",
    "\n",
    "def predict_game(team_1_vector, team_2_vector, home):\n",
    "    diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n",
    "    diff.append(home)\n",
    "    # Depending on the model you use, you will either need to return model.predict_proba or model.predict\n",
    "    # predict_proba = Linear Reg, Linear SVC\n",
    "    # predict = Gradient Boosted\n",
    "\n",
    "    return model.predict_proba([diff])[0][1]\n",
    "    #return model.predict([diff])[0]\n",
    "\n",
    "def create_prediction():\n",
    "    if os.path.exists(\"result.csv\"):\n",
    "        os.remove(\"result.csv\")\n",
    "    # The years that we want to predict for\n",
    "    years = range(2014,2018)\n",
    "    list_dictionaries = load_team_vectors(years)\n",
    "    print (\"Loaded the team vectors\")\n",
    "    results = [[0 for x in range(2)] for x in range(len(submission.index))]\n",
    "    for index, row in submission.iterrows():\n",
    "        matchup = row['ID']\n",
    "        year = int(matchup[0:4])\n",
    "        team_vectors = list_dictionaries[year - years[0]]\n",
    "        team_1_ID = int(matchup[5:9])\n",
    "        team_2_ID = int(matchup[10:14])\n",
    "        team_1_vector = team_vectors[team_1_ID]\n",
    "        team_2_vector = team_vectors[team_2_ID]\n",
    "        pred = predict_game(team_1_vector, team_2_vector, 0)\n",
    "        results[index][0] = matchup\n",
    "        results[index][1] = pred\n",
    "    results = pd.np.array(results)\n",
    "    first_row = [[0 for x in range(2)] for x in range(1)]\n",
    "    first_row[0][0] = 'ID'\n",
    "    first_row[0][1] = 'Pred'\n",
    "    with open(\"result_nusvc.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(first_row)\n",
    "        writer.writerows(results)\n",
    "    print('All Done!')\n",
    "create_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
